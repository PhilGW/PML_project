<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>PML Project: Predicting from Exercise Data by PhilGW</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">PML Project: Predicting from Exercise Data</h1>
      <h2 class="project-tagline"></h2>
      <a href="https://github.com/PhilGW/PML_project" class="btn">View on GitHub</a>
      <a href="https://github.com/PhilGW/PML_project/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/PhilGW/PML_project/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <p>&lt;!DOCTYPE html&gt;</p>

<p></p>

<p></p>

<p>

</p>

<p></p>

<p></p>

<p></p>Practical Machine Learning Project: Exercise Prediction



<p>
</p>







code{white-space: pre;}

<p></p>




  pre:not([class]) {
    background-color: white;
  }




<p></p>

<p></p>


.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img { 
  max-width:100%; 
  height: auto; 
}


<div>


<div id="header">
<h1>
<a id="practical-machine-learning-project-exercise-prediction" class="anchor" href="#practical-machine-learning-project-exercise-prediction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Practical Machine Learning Project: Exercise Prediction</h1>
<h4>
<a id="philgw" class="anchor" href="#philgw" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>PhilGW</em>
</h4>
<h4>
<a id="october-21-2015" class="anchor" href="#october-21-2015" aria-hidden="true"><span class="octicon octicon-link"></span></a><em>October 21, 2015</em>
</h4>
</div>

<div id="overview">
<h4>
<a id="overview" class="anchor" href="#overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>Overview</h4>
<p>The purpose of this project is to use machine learning to predict how physical exercise is being performed based on data from the exercise. Participants in the study under consideration were outfitted with a variety of sensors, and then asked to perform an exercise (barbell lifts) in a variety of correct and incorrect ways. The goal is to predict from a training set what type of lift was performed. The types of lifts are assigned a letter A through E, and this is the response that the algorithm will be attempting to fit.</p>
</div>

<div id="loading-and-splitting-the-data">
<h4>
<a id="loading-and-splitting-the-data" class="anchor" href="#loading-and-splitting-the-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Loading and Splitting the Data</h4>
<p>First, the libraries were loaded, and data were loaded from the working directory:</p>
<pre><code>library(caret); library(randomForest)</code></pre>
<pre><code>## Warning: package 'caret' was built under R version 3.2.2</code></pre>
<pre><code>## Loading required package: lattice
## Loading required package: ggplot2</code></pre>
<pre><code>## Warning: package 'ggplot2' was built under R version 3.2.1</code></pre>
<pre><code>## Warning: package 'randomForest' was built under R version 3.2.2</code></pre>
<pre><code>## randomForest 4.6-12
## Type rfNews() to see new features/changes/bug fixes.</code></pre>
<pre><code>fullset &lt;- read.csv("pml-training.csv", stringsAsFactors=FALSE, na.strings=c("","#DIV/0!", "NA" ))</code></pre>
<p>Next, the data were divided into a training and test set:</p>
<pre><code>set.seed(4700)
inTrain &lt;- createDataPartition(fullset$classe, p = 0.7, list=FALSE)
trainset &lt;- fullset[inTrain,]
testset &lt;- fullset[-inTrain,]</code></pre>
</div>

<div id="data-processing">
<h4>
<a id="data-processing" class="anchor" href="#data-processing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data Processing</h4>
<p>Much of the data is extraneous, or problematic because of ‘NA’ values.</p>
<p>The number of columns was reduced by: 1.) Eliminating columns that had nothing to do with the data collected by sensors…</p>
<pre><code>trset &lt;- trainset[,8:159]
ncol(trset) #Display the # of columns remaining</code></pre>
<pre><code>## [1] 152</code></pre>
<p>2.) by using the nearZeroVar() function with default settings to eliminate variables that don’t add much predictive value…</p>
<pre><code>nzv &lt;- nearZeroVar(trset, saveMetrics=TRUE)
finaltr &lt;- subset(trset,select=(nzv$nzv==FALSE)) #Eliminate columns flagged as poor predictors
ncol(finaltr)  #Display the # of columns remaining</code></pre>
<pre><code>## [1] 121</code></pre>
<p>3.) by eliminating all columns that contain NAs.</p>
<pre><code>nalist &lt;- sapply(finaltr, function(n) sum(is.na(n)) )
finaltr &lt;- finaltr[,nalist==0] #Eliminate columns with 1 or more NAs
ncol(finaltr)  #Display the # of columns remaining</code></pre>
<pre><code>## [1] 52</code></pre>
<p>The response of interest, “classe”, was added back to the set as the first column after these other actions were complete.</p>
<pre><code>finaltr &lt;- cbind(trainset$classe, finaltr); names(finaltr)[1] &lt;- "classe"
ncol(finaltr) #Display the # of columns</code></pre>
<pre><code>## [1] 53</code></pre>
<p>As can be seen, this takes the original dataset (which has 160 columns) and reduces it to a much more manageable dataset with only 52 predictors plus the outcome of interest.</p>
</div>

<div id="cross-validation">
<h4>
<a id="cross-validation" class="anchor" href="#cross-validation" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cross-Validation</h4>
<p>The algorithm used was Random Forests, which has a high tendency for overfitting, so cross-validation was used to ensure that the model did not simply fit the noise, and also to gain an estimate of the predictive accuracy.</p>
<pre><code>cvtest &lt;- rfcv(finaltr[,-1], finaltr[,1], cv.fold=6)
plot(cvtest$n.var, cvtest$error.cv, pch=19, log="x") #Plot error vs. # of predictors</code></pre>
<p><img title alt width="480"></p>
<p>As can be seen from the plot of the cross validation results, the general trend is that as the number of predictor variables used by the model increases, the expected error drops off. The values plotted above can be also be viewed in a table:</p>
<pre><code>data.frame(NumVar=cvtest$n.var, EstimatedErr=cvtest$error.cv)</code></pre>
<pre><code>##    NumVar EstimatedErr
## 52     52  0.007134018
## 26     26  0.009536289
## 13     13  0.011065007
## 6       6  0.046807891
## 3       3  0.138967751
## 1       1  0.601805343</code></pre>
<p>As can be seen, the model incorporating all 52 predictors from the dataset has the lowest error rate. Since processing time is not a major issue, the final model will incorporate all 52 predictors. Since the error rate as estimated by rfcv() is &lt;0.01, we expect greater than 99% accuracy when we apply the resulting model to the test set.</p>
</div>

<div id="building-the-model">
<h4>
<a id="building-the-model" class="anchor" href="#building-the-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Building the model</h4>
<p>The model was built using the randomForest() algorithm, from the randomForest package. As described above, cross-validation suggested that the best course of action was to incorporate all 52 predictors in the training set.</p>
<pre><code>rffit &lt;- randomForest(finaltr[,-1], as.factor(finaltr$classe) )</code></pre>
<p>From the cross-validation, it is expected that accuracy will be &gt;99%. This was tested by using the model to predict the 30% of results that were set aside in the test set:</p>
<pre><code>#Subset to only those 52 best predictors as identified by the training set:
finalte &lt;- testset[, colnames(testset) %in% colnames(finaltr) ]
finalte &lt;- subset(finalte, select= -classe )   #Eliminate the outcome
pred = predict(rffit,newdata=finalte)          #Generate model predictions
confusionMatrix(pred, testset$classe)          #Display result</code></pre>
<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1674    3    0    0    0
##          B    0 1135    1    0    0
##          C    0    1 1024   11    0
##          D    0    0    1  951    0
##          E    0    0    0    2 1082
## 
## Overall Statistics
##                                          
##                Accuracy : 0.9968         
##                  95% CI : (0.995, 0.9981)
##     No Information Rate : 0.2845         
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
##                                          
##                   Kappa : 0.9959         
##  Mcnemar's Test P-Value : NA             
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   0.9965   0.9981   0.9865   1.0000
## Specificity            0.9993   0.9998   0.9975   0.9998   0.9996
## Pos Pred Value         0.9982   0.9991   0.9884   0.9989   0.9982
## Neg Pred Value         1.0000   0.9992   0.9996   0.9974   1.0000
## Prevalence             0.2845   0.1935   0.1743   0.1638   0.1839
## Detection Rate         0.2845   0.1929   0.1740   0.1616   0.1839
## Detection Prevalence   0.2850   0.1930   0.1760   0.1618   0.1842
## Balanced Accuracy      0.9996   0.9981   0.9978   0.9932   0.9998</code></pre>
<p>As can be seen from the confusionMatrix() results, accuracy was 99.6% as predicted by the rfcv() cross-validation. Since the test set was kept separate from the training set from the very beginning, it is expected that the out-of-sample performance would be very similar on other test sets.</p>
<p>Finally, the same model was used to predict the 20 “mystery rows” from the test set included from the assignment:</p>
<pre><code>test20 &lt;- read.csv("pml-testing.csv", stringsAsFactors=FALSE, na.strings=c("","#DIV/0!", "NA" ))
finaltest20 &lt;- test20[, colnames(test20) %in% colnames(finaltr) ]
pred2 = predict(rffit,newdata=finaltest20)</code></pre>
<p>Entering these on the course website confirmed that all were correct.</p>
<p>This modeling exercise shows the ease with which random forests can be used to achieve highly accurate predictions on a high-dimensional data set. Cross-validation helped to ensure that overfitting did not occur; however, if new data were added, it would be important to include a random mixture of the new data in the training set to ensure that the model was not overfitted to the old data.</p>
</div>

<p></p>
</div>







<p>
</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/PhilGW/PML_project">PML Project: Predicting from Exercise Data</a> is maintained by <a href="https://github.com/PhilGW">PhilGW</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
